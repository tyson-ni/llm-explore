{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering using a search API and re-ranking\n",
    "\n",
    "Searching for relevant information can sometimes feel like looking for a needle in a haystack, but don’t despair, GPTs can actually do a lot of this work for us. In this guide we explore a way to augment existing search systems with various AI techniques, helping us sift through the noise.\n",
    "\n",
    "Two ways of retrieving information for GPT are:\n",
    "\n",
    "1. **Mimicking Human Browsing:** [GPT triggers a search](https://openai.com/blog/chatgpt-plugins#browsing), evaluates the results, and modifies the search query if necessary. It can also follow up on specific search results to form a chain of thought, much like a human user would do.\n",
    "2. **Retrieval with Embeddings:** Calculate [embeddings](https://platform.openai.com/docs/guides/embeddings) for your content and a user query, and then [retrieve the content](Question_answering_using_embeddings.ipynb) most related as measured by cosine similarity. This technique is [used heavily](https://blog.google/products/search/search-language-understanding-bert/) by search engines like Google.\n",
    "\n",
    "These approaches are both promising, but each has their shortcomings: the first one can be slow due to its iterative nature and the second one requires embedding your entire knowledge base in advance, continuously embedding new content and maintaining a vector database.\n",
    "\n",
    "By combining these approaches, and drawing inspiration from [re-ranking](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) methods, we identify an approach that sits in the middle. **This approach can be implemented on top of any existing search system, like the Slack search API, or an internal ElasticSearch instance with private data**. Here’s how it works:\n",
    "\n",
    "![search_augmented_by_query_generation_and_embeddings_reranking.png](../images/search_rerank_answer.png)\n",
    "\n",
    "**Step 1: Search**\n",
    "\n",
    "1.  User asks a question.\n",
    "2.  GPT generates a list of potential queries.\n",
    "3.  Search queries are executed in parallel.\n",
    "\n",
    "**Step 2: Re-rank**\n",
    "\n",
    "1.  Embeddings for each result are used to calculate semantic similarity to a generated hypothetical ideal answer to the user question.\n",
    "2.  Results are ranked and filtered based on this similarity metric.\n",
    "\n",
    "**Step 3: Answer**\n",
    "\n",
    "1.  Given the top search results, the model generates an answer to the user’s question, including references and links.\n",
    "\n",
    "This hybrid approach offers relatively low latency and can be integrated into any existing search endpoint, without requiring the upkeep of a vector database. Let's dive into it! We will use the [News API](https://newsapi.org/) as an example domain to search over.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In addition to your `OPENAI_API_KEY`, you'll have to include a `NEWS_API_KEY` in your environment. You can get an API key [here](https://newsapi.org/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env NEWS_API_KEY = YOUR_NEWS_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from datetime import date, timedelta  # date handling for fetching recent news\n",
    "from IPython import display  # for pretty printing\n",
    "import json  # for parsing the JSON api responses and model outputs\n",
    "from numpy import dot  # for cosine similarity\n",
    "import openai  # for using GPT and getting embeddings\n",
    "import os  # for loading environment variables\n",
    "import requests  # for making the API requests\n",
    "from tqdm.notebook import tqdm  # for printing progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "news_api_key = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def json_gpt(input: str):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n",
    "            {\"role\": \"user\", \"content\": input},\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    text = completion.choices[0].message.content\n",
    "    parsed = json.loads(text)\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def embeddings(input: list[str]) -> list[list[str]]:\n",
    "    response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=input)\n",
    "    return [data.embedding for data in response.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Search\n",
    "\n",
    "It all starts with a user question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User asks a question\n",
    "USER_QUESTION = \"Which famous American writer passed away in June 2023? Tell me about his or her work.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to be as exhaustive as possible, we use the model to generate a list of diverse queries based on this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['famous American writer death June 2023', 'American author death 2023', 'writer obituary June 2023', 'author passing June 2023', 'writer death bio', 'American writer legacy', 'author achievements', 'famous writer bibliography', 'American novelist death news', 'writer biography', 'author literary works', 'writer contribution to literature', 'Which famous American writer passed away in June 2023? Tell me about his or her work.']\n"
     ]
    }
   ],
   "source": [
    "QUERIES_INPUT = f\"\"\"\n",
    "You have access to a search API that returns recent news articles.\n",
    "Generate an array of search queries that are relevant to this question.\n",
    "Use a variation of related keywords for the queries, trying to be as general as possible.\n",
    "Include as many queries as you can think of, including and excluding terms.\n",
    "For example, include queries like ['keyword_1 keyword_2', 'keyword_1', 'keyword_2'].\n",
    "Be creative. \n",
    "Please be concise and include only the keywords in the queries. \n",
    "The more queries you include, the more likely you are to find relevant results.\n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"queries\": [\"query_1\", \"query_2\", \"query_3\"]}}\n",
    "\"\"\"\n",
    "\n",
    "queries = json_gpt(QUERIES_INPUT)[\"queries\"]\n",
    "\n",
    "# Let's include the original question as well for good measure\n",
    "queries.append(USER_QUESTION)\n",
    "\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The queries look good, so let's run the searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009913921356201172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e71c93969444124b81f06d619df9230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles: 357\n",
      "Top 5 articles of query 1: \n",
      "\n",
      "Title: 15 Trivia Tidbits About ‘All in the Family’\n",
      "Description: By Zanandi Botes Published: June 13th, 2023\n",
      "Content: The program you are about to see is All in the Family. It seeks to throw a humorous spotlight on our...\n",
      "\n",
      "Title: This week on \"Sunday Morning\" (June 11)\n",
      "Description: A look at the features for this week's broadcast of the #1 Sunday morning news program, hosted by Jane Pauley.\n",
      "Content: The Emmy Award-winning \"CBS News Sunday Morning\" is broadcast on CBS Sundays beginning at 9:00 a.m. ...\n",
      "\n",
      "Title: Apple TV+ shows and movies: Everything to watch on Apple TV Plus\n",
      "Description: Apple TV+ offers exclusive Apple original TV shows and movies in 4K HDR quality. You can watch across all of your screens and pick up where you left off on any device. Apple TV+ costs $6.99 per month. Here’s every Apple original television show and movie avai…\n",
      "Content: Apple TV+ offers exclusive Apple original TV shows and movies in 4K HDR quality. You can watch acros...\n",
      "\n",
      "Title: Apple TV+ shows and movies: Everything to watch on Apple TV Plus\n",
      "Description: Apple TV+ offers exclusive Apple original TV shows and movies in 4K HDR quality. You can watch across all of your screens and pick up where you left off on any device. Apple TV+ costs $6.99 per month. Here’s every Apple original television show and movie avai…\n",
      "Content: Apple TV+ offers exclusive Apple original TV shows and movies in 4K HDR quality. You can watch acros...\n",
      "\n",
      "Title: New This Week on Blu-ray and 4K UHD [June 13, 2023]\n",
      "Description: John Wick: Chapter 4 (Amazon Exclusive) - John Wick (Keanu Reeves) uncovers a path to defeating The High Table. But before he can earn his freedom, Wick must face off against a new enemy with powerful alliances across the globe and forces that turn old friend…\n",
      "Content: John Connor [Celluloid 06.12.23] scifihorroractionthrilleradventureJohn Wick: Chapter 4 (Amazon Excl...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search_news(\n",
    "    query: str,\n",
    "    news_api_key: str = news_api_key,\n",
    "    num_articles: int = 50,\n",
    "    from_datetime: str = \"2023-06-05\", \n",
    "    to_datetime: str = \"2023-06-19\",\n",
    ") -> dict:\n",
    "    response = requests.get(\n",
    "        \"https://newsapi.org/v2/everything\",\n",
    "        params={\n",
    "            \"q\": query,\n",
    "            \"apiKey\": news_api_key,\n",
    "            \"pageSize\": num_articles,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"from\": from_datetime,\n",
    "            \"to\": to_datetime,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "articles = []\n",
    "\n",
    "for query in tqdm(queries):\n",
    "    result = search_news(query)\n",
    "    if result[\"status\"] == \"ok\":\n",
    "        articles = articles + result[\"articles\"]\n",
    "    else:\n",
    "        raise Exception(result[\"message\"])\n",
    "\n",
    "# remove duplicates\n",
    "articles = list({article[\"url\"]: article for article in articles}.values())\n",
    "\n",
    "print(\"Total number of articles:\", len(articles))\n",
    "print(\"Top 5 articles of query 1:\", \"\\n\")\n",
    "\n",
    "for article in articles[0:5]:\n",
    "    print(\"Title:\", article[\"title\"])\n",
    "    print(\"Description:\", article[\"description\"])\n",
    "    print(\"Content:\", article[\"content\"][0:100] + \"...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, oftentimes, the search queries will return a large number of results, many of which are not relevant to the original question asked by the user. In order to improve the quality of the final answer, we use embeddings to re-rank and filter the results.\n",
    "\n",
    "# 2. Re-rank\n",
    "\n",
    "Drawing inspiration from [HyDE (Gao et al.)](https://arxiv.org/abs/2212.10496), we first generate a hypothetical ideal answer to rerank our compare our results against. This helps prioritize results that look like good answers, rather than those similar to our question. Here’s the prompt we use to generate our hypothetical answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Twain passed away in June 2023. He was known for his witty and satirical writing, with notable works such as The Adventures of NAME Finn and The NAME of the NAME. His writing often tackled social issues and provided commentary on American life during his time.\n"
     ]
    }
   ],
   "source": [
    "HA_INPUT = f\"\"\"\n",
    "Generate a hypothetical answer to the user's question. This answer which will be used to rank search results. \n",
    "Pretend you have all the information you need to answer, but don't use any actual facts. Instead, use placeholders\n",
    "like NAME did something, or NAME said something at PLACE. Also pretend you are in the year 2030 and have access to all the knowledge up to that year. \n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"hypotheticalAnswer\": \"hypothetical answer text\"}}\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_answer = json_gpt(HA_INPUT)[\"hypotheticalAnswer\"]\n",
    "\n",
    "print(hypothetical_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate embeddings for the search results and the hypothetical answer. We then calculate the cosine distance between these embeddings, giving us a semantic similarity metric. Note that we can simply calculate the dot product in lieu of doing a full cosine similarity calculation since the OpenAI embeddings are returned normalized in our API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6962791375040007,\n",
       " 0.7181057968180035,\n",
       " 0.6612304187122091,\n",
       " 0.661220916024921,\n",
       " 0.7087449610313865,\n",
       " 0.7846035385705046,\n",
       " 0.716807401567893,\n",
       " 0.6982201729846651,\n",
       " 0.7489642967838637,\n",
       " 0.6937529201134262]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_answer_embedding = embeddings(hypothetical_answer)[0]\n",
    "article_embeddings = embeddings(\n",
    "    [\n",
    "        f\"{article['title']} {article['description']} {article['content'][0:100]}\"\n",
    "        for article in articles\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarities = []\n",
    "for article_embedding in article_embeddings:\n",
    "    cosine_similarities.append(dot(hypothetical_answer_embedding, article_embedding))\n",
    "\n",
    "cosine_similarities[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use these similarity scores to sort and filter the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 articles: \n",
      "\n",
      "Title: Cormac McCarthy, revered American novelist, dies at 89\n",
      "Description: NEW YORK - Celebrated author Cormac McCarthy, an unflinching chronicler of America's bleak frontiers and grim underbelly, died on Tuesday aged 89, his publisher said.\n",
      "Content: NEW YORK - Celebrated author Cormac McCarthy, an unflinching chronicler of America's bleak frontiers...\n",
      "Score: 0.8271407791897417\n",
      "\n",
      "Title: Great American Novelist Cormac McCarthy Boldly Waded Into The Bleakness Of The Human Condition\n",
      "Description: McCarthy explored how even a 'Christianized' American can remain a violent wilderness in search of God and meaning.\n",
      "Content: Quintessentially American novelist Cormac McCarthy died on Tuesday, June 13, 2023. Since his death, ...\n",
      "Score: 0.8244918938044037\n",
      "\n",
      "Title: Cormac McCarthy, Revered American Novelist, Dies At 89\n",
      "Description: Celebrated author Cormac McCarthy, an unflinching chronicler of America's bleak frontiers and grim underbelly, died on Tuesday aged 89, his publisher said.\n",
      "Content: Cormac McCarthy, the Pulitzer Prize-winning novelist who wrote \"The Road\" and \"No Country for Old Me...\n",
      "Score: 0.8211298941056193\n",
      "\n",
      "Title: Cormac McCarthy, revered American novelist, dies at 89\n",
      "Description: Celebrated author Cormac McCarthy, an unflinching chronicler of America's bleak frontiers and grim underbelly, died on Tuesday aged 89, his publisher said. The Pulitzer Prize-winning novelist who wrote &quot;The Road&quot; and &quot;No Country for Old Men&quo…\n",
      "Content: Celebrated author Cormac McCarthy, an unflinching chronicler of America's bleak frontiers and grim u...\n",
      "Score: 0.8145666870741505\n",
      "\n",
      "Title: Cormac McCarthy, among America's greatest authors, dies at 89\n",
      "Description: Cormac McCarthy, long considered one of America's greatest writers for his violent and bleak depictions of the United States and its borderlands in novels like \"Blood Meridian,\" \"The Road\" and \"All the Pretty Horses,\" died on Tuesday, according to his Penguin…\n",
      "Content: Cormac McCarthy, long considered one of Americas greatest writers for his violent and bleak depictio...\n",
      "Score: 0.8134215641004402\n",
      "\n",
      "Title: Cormac McCarthy showed us America’s violent heart | Martin Pengelly\n",
      "Description: With mordant wit and stark description, the literary great wove a tapestry of anger, humour, decency and bad behaviour – and of the perpetual terror of man<ul><li>Cormac McCarthy, celebrated US novelist, dies aged 89</li><li>A life in quotes: Cormac McCarthy<…\n",
      "Content: Cormac McCarthy, who died on Tuesday aged 89, achieved fame relatively late. He was nearly 60 when, ...\n",
      "Score: 0.8103722855349912\n",
      "\n",
      "Title: 'Maybe the greatest American novelist of my time': Cormac McCarthy honored by Stephen King and others\n",
      "Description: Stephen King and others honor author Cormac McCarthy, who died of natural causes on Tuesday at age 89.\n",
      "Content: The literary world lost one of its icons on Tuesday when No Country for Old Men and The Road author ...\n",
      "Score: 0.8095520087274358\n",
      "\n",
      "Title: Cormac McCarthy remembered: ‘His work will sing down the centuries’\n",
      "Description: The celebrated US author of Blood Meridian, The Road and No Country for Old Men has died. Here, leading contemporaries and critics pay tribute to him• Cormac McCarthy, celebrated US novelist, dies aged 89British writer and fellow of Emmanuel College, Cambridg…\n",
      "Content: Robert Macfarlane. Photograph: www.foxtrotfilms.com\r\n",
      "Robert Macfarlane: He listened harder to prose ...\n",
      "Score: 0.8067701485571332\n",
      "\n",
      "Title: Acclaimed US novelist Cormac McCarthy dies at 89\n",
      "Description: Known for his dark tales of Americana, including No Country for Old Men, McCarthy was an icon in modern US literature.\n",
      "Content: Cormac McCarthy, whose nihilistic and violent tales of the United States frontier and post-apocalypt...\n",
      "Score: 0.8060943165897994\n",
      "\n",
      "Title: Legendary American Author Cormac McCarthy Dies, Aged 89\n",
      "Description: Cormac McCarthy, the Pulitzer Prize-winning American novelist, died this week, aged 89 years old. The writer died from natural causes, leaving a huge gap in ... Read More\n",
      "Content: Cormac McCarthy, the Pulitzer Prize-winning American novelist, died this week, aged 89 years old. Th...\n",
      "Score: 0.8027768100931316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scored_articles = zip(articles, cosine_similarities)\n",
    "\n",
    "# Sort articles by cosine similarity\n",
    "sorted_articles = sorted(scored_articles, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print top 5 articles\n",
    "print(\"Top 5 articles:\", \"\\n\")\n",
    "\n",
    "for article, score in sorted_articles[0:10]:\n",
    "    print(\"Title:\", article[\"title\"])\n",
    "    print(\"Description:\", article[\"description\"])\n",
    "    print(\"Content:\", article[\"content\"][0:100] + \"...\")\n",
    "    print(\"Score:\", score)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8271407791897417,\n",
       " 0.8244918938044037,\n",
       " 0.8211298941056193,\n",
       " 0.8145666870741505,\n",
       " 0.8134215641004402,\n",
       " 0.8103722855349912,\n",
       " 0.8095520087274358,\n",
       " 0.8067701485571332,\n",
       " 0.8060943165897994,\n",
       " 0.8027768100931316,\n",
       " 0.8023430179372025,\n",
       " 0.8018686253231713,\n",
       " 0.7991268498142123,\n",
       " 0.7989662834219854,\n",
       " 0.7960174867696671,\n",
       " 0.7955277816338275,\n",
       " 0.7954717275490183,\n",
       " 0.792841239391181,\n",
       " 0.7927699058886994,\n",
       " 0.7925346097681247]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s[1] for s in sorted_articles[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! These results look a lot more relevant to our original query. Now, let's use the top 20 results to generate a final answer.\n",
    "\n",
    "## 3. Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Cormac McCarthy, a celebrated American novelist known for his unflinching depictions of America's bleak frontiers and grim underbelly, passed away in June 2023 at the age of 89. McCarthy was a Pulitzer Prize-winning author who wrote acclaimed works such as \"The Road,\" \"No Country for Old Men,\" and \"Blood Meridian.\" His writing often explored the violence and darkness of the human condition, and his work has been hailed as some of the greatest American literature of the modern era. For more information on McCarthy's life and work, you can read articles from [Bangkok Post](https://www.bangkokpost.com/world/2591170/cormac-mccarthy-revered-american-novelist-dies-at-89), [The Federalist](https://thefederalist.com/2023/06/15/great-american-novelist-cormac-mccarthy-boldly-waded-into-the-bleakness-of-the-human-condition/), [IBTimes](https://www.ibtimes.com/cormac-mccarthy-revered-american-novelist-dies-89-3699623), [Japan Today](https://japantoday.com/category/world/cormac-mccarthy-revered-american-novelist-dies-at-891), and [CNN](https://www.cnn.com/style/article/cormac-mccarthy-author-death/index.html)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_top_results = [\n",
    "    {\n",
    "        \"title\": article[\"title\"],\n",
    "        \"description\": article[\"description\"],\n",
    "        \"url\": article[\"url\"],\n",
    "    }\n",
    "    for article, _score in sorted_articles[0:5]\n",
    "]\n",
    "\n",
    "ANSWER_INPUT = f\"\"\"\n",
    "Generate an answer to the user's question based on the given search results. \n",
    "TOP_RESULTS: {formatted_top_results}\n",
    "USER_QUESTION: {USER_QUESTION}\n",
    "\n",
    "Include as much information as possible in the answer. Reference the relevant search result urls as markdown links.\n",
    "\"\"\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": ANSWER_INPUT}],\n",
    "    temperature=0.5,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "text = \"\"\n",
    "for chunk in completion:\n",
    "    text += chunk.choices[0].delta.get(\"content\", \"\")\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(display.Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
