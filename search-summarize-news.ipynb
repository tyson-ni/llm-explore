{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search and Summarize News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from datetime import date, timedelta  # date handling for fetching recent news\n",
    "from IPython import display  # for pretty printing\n",
    "import json  # for parsing the JSON api responses and model outputs\n",
    "from numpy import dot  # for cosine similarity\n",
    "import openai  # for using GPT and getting embeddings\n",
    "import os  # for loading environment variables\n",
    "import requests  # for making the API requests\n",
    "from tqdm.notebook import tqdm  # for printing progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Recently, the Federal Reserve paused its interest rate hikes but signaled that more tightening could be coming in the future. This decision has received mixed commentary, with some economists speculating that it could be a \"bluff\" or a \"skip.\" The Fed has also been criticized for its handling of inflation, with figures like Elon Musk and Mohamed El-Erian speaking out against the central bank's policies. Additionally, a World Bank report has warned that the Fed's fight against inflation could have global economic consequences. For more information, see [this article](https://markets.businessinsider.com/news/stocks/fed-elon-musk-el-erian-siegel-rosenberg-inflation-interest-rates-2023-5) and [this one](https://finance.yahoo.com/news/federal-reserve-economists-mixed-on-whether-fed-pause-is-a-bluff-or-a-skip-204727069.html)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "news_api_key = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# User asks a question\n",
    "USER_QUESTION = \"Recap actions the Federal Reserve took recently and surrounding commentary\"\n",
    "\n",
    "# Helper functions\n",
    "def json_gpt(input: str):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n",
    "            {\"role\": \"user\", \"content\": input},\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    text = completion.choices[0].message.content\n",
    "    parsed = json.loads(text)\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def embeddings(input: list[str]) -> list[list[str]]:\n",
    "    response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=input)\n",
    "    return [data.embedding for data in response.data]\n",
    "\n",
    "QUERIES_INPUT = f\"\"\"\n",
    "You have access to a search API that returns recent news articles.\n",
    "Generate an array of search queries that are relevant to this question.\n",
    "Use a variation of related keywords for the queries, trying to be as general as possible.\n",
    "Include as many queries as you can think of, including and excluding terms.\n",
    "For example, include queries like ['keyword_1 keyword_2', 'keyword_1', 'keyword_2'].\n",
    "Be creative. \n",
    "Please be concise and include only the keywords in the queries. \n",
    "The more queries you include, the more likely you are to find relevant results.\n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"queries\": [\"query_1\", \"query_2\", \"query_3\"]}}\n",
    "\"\"\"\n",
    "\n",
    "queries = json_gpt(QUERIES_INPUT)[\"queries\"]\n",
    "\n",
    "print(queries)\n",
    "\n",
    "# Let's include the original question as well for good measure\n",
    "queries.append(USER_QUESTION)\n",
    "\n",
    "def search_news(\n",
    "    query: str,\n",
    "    news_api_key: str = news_api_key,\n",
    "    num_articles: int = 50,\n",
    "    from_datetime: str = \"2023-05-21\", \n",
    "    to_datetime: str = \"2023-06-16\",\n",
    ") -> dict:\n",
    "    response = requests.get(\n",
    "        \"https://newsapi.org/v2/everything\",\n",
    "        params={\n",
    "            \"q\": query,\n",
    "            \"apiKey\": news_api_key,\n",
    "            \"pageSize\": num_articles,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"from\": from_datetime,\n",
    "            \"to\": to_datetime,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "articles = []\n",
    "\n",
    "for query in tqdm(queries):\n",
    "    result = search_news(query)\n",
    "    if result[\"status\"] == \"ok\":\n",
    "        articles = articles + result[\"articles\"]\n",
    "    else:\n",
    "        raise Exception(result[\"message\"])\n",
    "\n",
    "# remove duplicates\n",
    "articles = list({article[\"url\"]: article for article in articles}.values())\n",
    "\n",
    "HA_INPUT = f\"\"\"\n",
    "Generate a hypothetical answer to the user's question. This answer which will be used to rank search results. \n",
    "Pretend you have all the information you need to answer, but don't use any actual facts. Instead, use placeholders\n",
    "like NAME did something, or NAME said something at PLACE. Also pretend you are in the year 2030 and have access to all the knowledge up to that year. \n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"hypotheticalAnswer\": \"hypothetical answer text\"}}\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_answer = json_gpt(HA_INPUT)[\"hypotheticalAnswer\"]\n",
    "\n",
    "hypothetical_answer_embedding = embeddings(hypothetical_answer)[0]\n",
    "article_embeddings = embeddings(\n",
    "    [\n",
    "        f\"{article['title']} {article['description']} {article['content'][0:100]}\"\n",
    "        for article in articles\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarities = []\n",
    "for article_embedding in article_embeddings:\n",
    "    cosine_similarities.append(dot(hypothetical_answer_embedding, article_embedding))\n",
    "    \n",
    "\n",
    "scored_articles = zip(articles, cosine_similarities)\n",
    "\n",
    "# Sort articles by cosine similarity\n",
    "sorted_articles = sorted(scored_articles, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "formatted_top_results = [\n",
    "    {\n",
    "        \"title\": article[\"title\"],\n",
    "        \"description\": article[\"description\"],\n",
    "        \"url\": article[\"url\"],\n",
    "    }\n",
    "    for article, _score in sorted_articles[0:5]\n",
    "]\n",
    "\n",
    "ANSWER_INPUT = f\"\"\"\n",
    "Generate an answer to the user's question based on the given search results. \n",
    "TOP_RESULTS: {formatted_top_results}\n",
    "USER_QUESTION: {USER_QUESTION}\n",
    "\n",
    "Include as much information as possible in the answer. Reference the relevant search result urls as markdown links.\n",
    "\"\"\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": ANSWER_INPUT}],\n",
    "    temperature=0.5,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "\n",
    "text = \"\"\n",
    "for chunk in completion:\n",
    "    text += chunk.choices[0].delta.get(\"content\", \"\")\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(display.Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Federal Reserve made several moves recently to stabilize the economy. According to commentary from experts, these actions were seen as necessary but controversial. Some argued that NAME, a prominent economist, had warned about the potential risks of these actions at a conference in PLACE. However, others praised the Federal Reserve for taking bold steps to prevent a recession.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
